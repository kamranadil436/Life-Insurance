{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    This class provides method to load data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        # print('in DataLoader')\n",
    "\n",
    "    def loader(self):\n",
    "        # print('Loading data.')\n",
    "        file = pd.read_csv(self.path)\n",
    "        # print('Finish loading')\n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = DataLoader(path='train.csv')\n",
    "train_data = train.loader()\n",
    "test = DataLoader(path='test.csv')\n",
    "test_data = test.loader()\n",
    "data = train_data.append(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess data #\n",
    "\n",
    "# factorize categorical variables\n",
    "data['Product_Info_2'] = pd.factorize(data['Product_Info_2'])[0]\n",
    "\n",
    "# drop id variable\n",
    "data = data.drop('Id', axis=1)\n",
    "\n",
    "# drop response variable\n",
    "data = data.drop('Response', axis=1)\n",
    "\n",
    "# data.to_csv('complete_data.csv')\n",
    "\n",
    "# feature scaling and standardisation/ normalisation\n",
    "def feature_scale(df):\n",
    "    scale_df = (df - df.mean()) / df.std(ddof=1)\n",
    "    return scale_df\n",
    "\n",
    "\n",
    "data = feature_scale(data)\n",
    "\n",
    "\n",
    "#  dealing missing value\n",
    "\n",
    "def check_missing(df):\n",
    "    # Explore missing data\n",
    "    missing_data = df.isnull().sum()\n",
    "    # print(missing_data.dtypes)\n",
    "    # print(type(missing_data))\n",
    "    total_data = len(df)\n",
    "    df_missing_data = missing_data.to_frame()\n",
    "    df_missing_data.columns = ['counts']\n",
    "    # Identify missing categories\n",
    "    df_missing_data = df_missing_data[df_missing_data.counts != 0]\n",
    "    # Calculate missing percentage\n",
    "    df_missing_data['missing_percent'] = df_missing_data.counts / total_data\n",
    "    print(df_missing_data)\n",
    "    print(len(df_missing_data))\n",
    "    return df_missing_data\n",
    "\n",
    "\n",
    "# check_missing(data)\n",
    "\n",
    "# Create list of variable types\n",
    "\n",
    "cont_variable_list = ['Product_Info_4', 'Ins_Age', 'Ht', 'Wt', 'BMI', 'Employment_Info_1', 'Employment_Info_4',\n",
    "                      'Employment_Info_6', 'Insurance_History_5', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4',\n",
    "                      'Family_Hist_5']\n",
    "\n",
    "dis_variable_list = ['Medical_History_1', 'Medical_History_10', 'Medical_History_15', 'Medical_History_24',\n",
    "                     'Medical_History_32']\n",
    "\n",
    "for i in range(48):\n",
    "    i += 1\n",
    "    dis_variable_list.append('Medical_Keyword_' + str(i))\n",
    "\n",
    "cat_variable_list = []\n",
    "for header in data.columns:\n",
    "    if header in cont_variable_list and dis_variable_list:\n",
    "        pass\n",
    "    else:\n",
    "        cat_variable_list.append(header)\n",
    "\n",
    "missing_list = ['Employment_Info_1', 'Employment_Info_4', 'Employment_Info_6', 'Family_Hist_2', 'Family_Hist_3',\n",
    "                'Family_Hist_4', 'Family_Hist_5', 'Insurance_History_5', 'Medical_History_1', 'Medical_History_10',\n",
    "                'Medical_History_15', 'Medical_History_24', 'Medical_History_32']\n",
    "\n",
    "\n",
    "# recommend method : pca, interpolation,svd, boosting\n",
    "\n",
    "class MissingMethod:\n",
    "    \"\"\"\n",
    "    This class will provide various method to handle missing values\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.df = data\n",
    "\n",
    "    def drop_response(self):\n",
    "        self.df = self.df.drop('Response', axis=1, inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def fill_mode(self):\n",
    "        for var in missing_list:\n",
    "            if var in dis_variable_list and cat_variable_list:\n",
    "                self.df[var] = self.df[var].fillna(self.df[var].mode()[0])\n",
    "        return self.df\n",
    "\n",
    "    def fill_avg(self):\n",
    "        for var in missing_list:\n",
    "            self.df[var] = self.df[var].fillna(self.df[var].mean())\n",
    "        return self.df\n",
    "\n",
    "    def drop_col(self):\n",
    "        self.df = self.df.drop(['Medical_History_10', 'Medical_History_24',\n",
    "                                'Medical_History_32'])\n",
    "        return self.df\n",
    "\n",
    "\n",
    "# preprocess = MissingMethod(data).fill_mode()\n",
    "# preprocess = MissingMethod(data).fill_avg()\n",
    "# check_missing(preprocess)\n",
    "# preprocess = MissingMethod(data)\n",
    "\n",
    "# use SVD to fill missing data\n",
    "# pls normalise the data before using this function\n",
    "# 1. if filling missing data, pls drop response\n",
    "# 2. if use it to predict response, pls keep response\n",
    "def fill_svd(df):\n",
    "    col_mean = np.nanmean(df, axis=0, keepdims=1)\n",
    "    valid = np.isfinite(df)\n",
    "    df0 = np.where(valid, df, col_mean)\n",
    "    halt = True\n",
    "    maxiter = 100\n",
    "    ii = 1\n",
    "    normlist = []\n",
    "    while halt == True:\n",
    "        U, s, V = np.linalg.svd(df0, full_matrices=False)\n",
    "        s1 = [(i * 0 if i <= 30 else i) for i in s]\n",
    "        df1 = U.dot(np.diag(s1).dot(V))\n",
    "        df2 = np.where(~valid, df1, df0)\n",
    "        norm = np.linalg.norm(df2 - df1)\n",
    "        normlist.append(norm)\n",
    "        #        print(norm)\n",
    "        df0 = df2\n",
    "        if norm < 0.00001 or ii >= maxiter:\n",
    "            halt = False\n",
    "            error = np.nansum((df1 - df) ** 2)\n",
    "        ii += 1\n",
    "    print(ii)\n",
    "    return df2, normlist, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add BMI*Ins_age\n",
    "data['BMI_Ins_age'] = data['BMI']*data['Ins_Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79146, 121)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chose features\n",
    "#  1. use LinearSVC with L1 C=0.01\n",
    "#   The number of the selected features = 89\n",
    "features = ['Product_Info_1','Product_Info_2', 'Product_Info_3', 'Product_Info_4', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7',\n",
    " 'Ins_Age', 'Ht', 'Wt', 'BMI', 'Employment_Info_1', 'Employment_Info_2', 'Employment_Info_3', 'Employment_Info_5', 'Employment_Info_6',\n",
    " 'InsuredInfo_1', 'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5','InsuredInfo_6', 'InsuredInfo_7',\n",
    " 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_7', 'Insurance_History_8',\n",
    " 'Insurance_History_9', 'Family_Hist_1', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5', 'Medical_History_1',\n",
    " 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7',\n",
    " 'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13',\n",
    " 'Medical_History_14', 'Medical_History_15', 'Medical_History_16', 'Medical_History_17', 'Medical_History_18', 'Medical_History_19',\n",
    " 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_24', 'Medical_History_25',\n",
    " 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', 'Medical_History_31',\n",
    " 'Medical_History_32', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_36', 'Medical_History_37',\n",
    " 'Medical_History_38', 'Medical_History_39', 'Medical_History_40', 'Medical_History_41', 'Medical_Keyword_1', 'Medical_Keyword_2',\n",
    " 'Medical_Keyword_3', 'Medical_Keyword_4', 'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7', 'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10', 'Medical_Keyword_12', 'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16',\n",
    " 'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19', 'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22',\n",
    " 'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25', 'Medical_Keyword_26', 'Medical_Keyword_28', 'Medical_Keyword_29',\n",
    " 'Medical_Keyword_30', 'Medical_Keyword_31', 'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_35', 'Medical_Keyword_36',\n",
    " 'Medical_Keyword_37', 'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40', 'Medical_Keyword_41', 'Medical_Keyword_42',\n",
    " 'Medical_Keyword_43', 'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46', 'Medical_Keyword_47', 'Medical_Keyword_48',\n",
    " 'BMI_Ins_age']\n",
    "data_3 = data[features]\n",
    "# type(data_3)\n",
    "data_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "# fill missing data\n",
    "# # average\n",
    "# data_average = MissingMethod(data).fill_avg()\n",
    "# data_average.head()\n",
    "# SVD\n",
    "data, list, error = fill_svd(data_3)\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.163431</td>\n",
       "      <td>-1.142966</td>\n",
       "      <td>-2.821329</td>\n",
       "      <td>-0.890333</td>\n",
       "      <td>-0.083038</td>\n",
       "      <td>-2.246073</td>\n",
       "      <td>-0.1492</td>\n",
       "      <td>1.180160</td>\n",
       "      <td>-1.683671</td>\n",
       "      <td>-1.611867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245961</td>\n",
       "      <td>-0.102065</td>\n",
       "      <td>-0.218231</td>\n",
       "      <td>-0.103259</td>\n",
       "      <td>-0.088131</td>\n",
       "      <td>-0.117674</td>\n",
       "      <td>-0.092677</td>\n",
       "      <td>-0.141054</td>\n",
       "      <td>-0.241129</td>\n",
       "      <td>-1.547628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.163431</td>\n",
       "      <td>-0.861071</td>\n",
       "      <td>0.315180</td>\n",
       "      <td>-0.890333</td>\n",
       "      <td>-0.083038</td>\n",
       "      <td>0.445216</td>\n",
       "      <td>-0.1492</td>\n",
       "      <td>-1.756901</td>\n",
       "      <td>-1.438982</td>\n",
       "      <td>-1.799149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245961</td>\n",
       "      <td>-0.102065</td>\n",
       "      <td>-0.218231</td>\n",
       "      <td>-0.103259</td>\n",
       "      <td>-0.088131</td>\n",
       "      <td>-0.117674</td>\n",
       "      <td>-0.092677</td>\n",
       "      <td>-0.141054</td>\n",
       "      <td>-0.241129</td>\n",
       "      <td>2.708761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.163431</td>\n",
       "      <td>-0.579176</td>\n",
       "      <td>0.315180</td>\n",
       "      <td>-0.890333</td>\n",
       "      <td>-0.083038</td>\n",
       "      <td>0.445216</td>\n",
       "      <td>-0.1492</td>\n",
       "      <td>-1.907520</td>\n",
       "      <td>0.518537</td>\n",
       "      <td>-0.043379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245961</td>\n",
       "      <td>-0.102065</td>\n",
       "      <td>-0.218231</td>\n",
       "      <td>-0.103259</td>\n",
       "      <td>-0.088131</td>\n",
       "      <td>-0.117674</td>\n",
       "      <td>-0.092677</td>\n",
       "      <td>-0.141054</td>\n",
       "      <td>-0.241129</td>\n",
       "      <td>0.509513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.163431</td>\n",
       "      <td>-0.297282</td>\n",
       "      <td>-2.821329</td>\n",
       "      <td>0.565558</td>\n",
       "      <td>-0.083038</td>\n",
       "      <td>0.445216</td>\n",
       "      <td>-0.1492</td>\n",
       "      <td>-1.229736</td>\n",
       "      <td>-0.460222</td>\n",
       "      <td>-0.979790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245961</td>\n",
       "      <td>-0.102065</td>\n",
       "      <td>-0.218231</td>\n",
       "      <td>-0.103259</td>\n",
       "      <td>-0.088131</td>\n",
       "      <td>-0.117674</td>\n",
       "      <td>-0.092677</td>\n",
       "      <td>-0.141054</td>\n",
       "      <td>-0.241129</td>\n",
       "      <td>1.050366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.163431</td>\n",
       "      <td>-0.015387</td>\n",
       "      <td>0.315180</td>\n",
       "      <td>-0.344374</td>\n",
       "      <td>-0.083038</td>\n",
       "      <td>0.445216</td>\n",
       "      <td>-0.1492</td>\n",
       "      <td>0.050521</td>\n",
       "      <td>-0.704912</td>\n",
       "      <td>-0.652046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245961</td>\n",
       "      <td>-0.102065</td>\n",
       "      <td>-0.218231</td>\n",
       "      <td>-0.103259</td>\n",
       "      <td>-0.088131</td>\n",
       "      <td>-0.117674</td>\n",
       "      <td>-0.092677</td>\n",
       "      <td>-0.141054</td>\n",
       "      <td>-0.241129</td>\n",
       "      <td>-0.149234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5       6    \\\n",
       "0 -0.163431 -1.142966 -2.821329 -0.890333 -0.083038 -2.246073 -0.1492   \n",
       "1 -0.163431 -0.861071  0.315180 -0.890333 -0.083038  0.445216 -0.1492   \n",
       "2 -0.163431 -0.579176  0.315180 -0.890333 -0.083038  0.445216 -0.1492   \n",
       "3 -0.163431 -0.297282 -2.821329  0.565558 -0.083038  0.445216 -0.1492   \n",
       "4 -0.163431 -0.015387  0.315180 -0.344374 -0.083038  0.445216 -0.1492   \n",
       "\n",
       "        7         8         9      ...          111       112       113  \\\n",
       "0  1.180160 -1.683671 -1.611867    ...    -0.245961 -0.102065 -0.218231   \n",
       "1 -1.756901 -1.438982 -1.799149    ...    -0.245961 -0.102065 -0.218231   \n",
       "2 -1.907520  0.518537 -0.043379    ...    -0.245961 -0.102065 -0.218231   \n",
       "3 -1.229736 -0.460222 -0.979790    ...    -0.245961 -0.102065 -0.218231   \n",
       "4  0.050521 -0.704912 -0.652046    ...    -0.245961 -0.102065 -0.218231   \n",
       "\n",
       "        114       115       116       117       118       119       120  \n",
       "0 -0.103259 -0.088131 -0.117674 -0.092677 -0.141054 -0.241129 -1.547628  \n",
       "1 -0.103259 -0.088131 -0.117674 -0.092677 -0.141054 -0.241129  2.708761  \n",
       "2 -0.103259 -0.088131 -0.117674 -0.092677 -0.141054 -0.241129  0.509513  \n",
       "3 -0.103259 -0.088131 -0.117674 -0.092677 -0.141054 -0.241129  1.050366  \n",
       "4 -0.103259 -0.088131 -0.117674 -0.092677 -0.141054 -0.241129 -0.149234  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3 = feature_scale(data)\n",
    "data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_3.to_csv('data_features2_SVD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
