{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice for applying the method created in this post\n",
    "==========================================================\n",
    "### files structure\n",
    "1. `path.py` : defines the paths of all kinds of data will be used below\n",
    "  * original data: `train.csv` \\ `test.csv`\n",
    "  * parsed data: `parsed_train.csv` \\  `parsed_test.csv`\n",
    "  * parsed normalized data: `parsed_train_normalized.csv` \\  `parsed_test_normalized.csv` \n",
    "\n",
    "<br>2. `preprocessing.py` : pre-process methods for tackling with original data set <br>\n",
    "<br>\n",
    "  &emsp;&emsp; *functions:*\n",
    "  * loadParseData: limited feature engineering, imputing missing values with mean or median according to feature's format\n",
    "  * fill_svd: returns complete data set where missing value imputed with svd method (execute after *loadParseData*)\n",
    "  * normalization: normalize data with MaxMin scaler\n",
    "  * et_selection: select features on ordered importances using **ExtraTreesClassifier** model\n",
    "  * svc_selection: select features with regulation using **LinearSVC** model \n",
    "\n",
    "<br>3. `paramsTuning.py` : tune parameter for different model with best cross-validation performance with **grid_search** method <br>\n",
    "  *class model_tuning_params consist of :*  \n",
    "  * \\__init__: specified with model name (xgb, rf, regress, svm), initilize corresponding models and parameters matrix for testing\n",
    "  * modelfit_xgb: specification for xgboost model with *xgb.cv*, returns best fitted parameters\n",
    "  * grid_search: general function for other models, return best fitted parameters<br>\n",
    "  \n",
    "<br>4. `ensemble.py` : a ensemble approach to feed the preliminary's predict probs back to training, train again with xgboost model <br>\n",
    "<br>5. `offset.py`: a approach to compensate the imbalanced dataset, adding predict's value with offset vector to make its distribution reasonable, the offset vector optimized with *fmin_powell* function with training data.  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline go-through:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "git clone git@github.com:Entheos1994/Entheos1994.github.io.git\n",
    "cd adml_dataminer\n",
    "pip install -r requirements.txt\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding pacakge path for import\n",
    "import sys \n",
    "import os\n",
    "path = os.getcwd()\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import path\n",
    "import path\n",
    "'''\n",
    "TRAIN_PATH\n",
    "TEST_PATH\n",
    "'''\n",
    "# preprocessing\n",
    "import pre_processing\n",
    "from pre_processing import *\n",
    "parsed_train, parsed_test = loadParseData()\n",
    "\n",
    "# svd imputing\n",
    "all_data = parsed_train.append(parsed_test)\n",
    "parsed_svd = fill_svd(all_data)\n",
    "\n",
    "# normalization\n",
    "parsed_train_normalized, parsed_test_normalized = normalization(parsed_train, parsed_test)\n",
    "\n",
    "# feature selection by extratrees using parsed_train (not normalized)\n",
    "# alternative 1. select features whose importances cumulated over 90% (can be tuned by the input: default_import)\n",
    "extra_feature_list_1 = et_selection(parsed_train, alternatives=False, default_import=0.9)\n",
    "\n",
    "# alternative 2. select features whose importances individually over 0.5%\n",
    "extra_feature_list_2 = et_selection(parsed_train, alternatives=True)\n",
    "\n",
    "\n",
    "# feature selection by SVC regression model using parsed_train_normalized (normalized)\n",
    "# alternative 1. select features using l1 regularization\n",
    "svc_feature_list = svc_selection(parsed_train_normalized, p='l1')\n",
    "\n",
    "# alternative 2. select feature using l2 regularization\n",
    "svc_feature_list = svc_selection(parsed_train_normalized, p='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the data\n"
     ]
    }
   ],
   "source": [
    "import pre_processing\n",
    "imp.reload(pre_processing)\n",
    "from pre_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import paramsTuning\n",
    "from paramsTuning import *\n",
    "xgb_model = model_tuning_params(model_name='xgb', random_seed=26)\n",
    "rf_model = model_tuning_params(model_name='rf', random_seed=26)\n",
    "svm_model = model_tuning_params(model_name='svm', random_seed=26)\n",
    "regress_model = model_tuning_params(model_name='regress', random_seed=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "would running for a long time for getting best parameters\n",
    "--------------------------------------------------------\n",
    "1.xgb \n",
    "xgb_best = xgb_model.model_xgb(dtrain=parsed_train, useTrainCV=True, cv_folds=5, early_stopping_rounds=50, metric='rmse',\n",
    "                     obt='reg:linear')\n",
    "xgb_best.model.get_params()\n",
    "\n",
    "\n",
    "2.random forest\n",
    "rf_best = rf_model.grid_search(parsed_train)\n",
    "rf_best.model.get_params()\n",
    "\n",
    "3.svm\n",
    "svm_best = svm_model.grid_search(parsed_train_normalized)\n",
    "svm_best.model.get_params()\n",
    "\n",
    "4.regress\n",
    "regress_best = regress_model.grid_search(parsed_train_normalized)\n",
    "regress_best.model.get_params()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### offset vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take regress model as example\n",
    "import offset\n",
    "from offset import *\n",
    "regress = deepcopy(regress_model.model)\n",
    "predictors = [col for col in parsed_train_normalized.columns.values if col not in ['Response', 'Id']]\n",
    "regress.fit(parsed_train_normalized[predictors], parsed_train_normalized['Response'])\n",
    "\n",
    "train_preds = regress.predict(parsed_train_normalized[predictors])\n",
    "test_preds = regress.predict(parsed_test_normalized[predictors])\n",
    "\n",
    "offseted_preds = offset_apply(train_preds, test_preds, parsed_train_normalized['Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ensemble \n",
    "from ensemble import *\n",
    "rf_class_model = rf_model.model\n",
    "xgb_class_model = xgb_model.model\n",
    "svm_class_model = svm_model.model\n",
    "regress_class_model = regress_model.model\n",
    "ensembled_pred = proba_ensemble(parsed_train, parsed_train_normalized, parsed_test, parsed_test_normalized)\n",
    "print(ensembled_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
